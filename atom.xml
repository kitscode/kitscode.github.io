<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>kev&#39;s blog</title>
  
  
  <link href="https://kevll.com/atom.xml" rel="self"/>
  
  <link href="https://kevll.com/"/>
  <updated>2022-12-19T10:51:53.487Z</updated>
  <id>https://kevll.com/</id>
  
  <author>
    <name>kevin</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CAP理论</title>
    <link href="https://kevll.com/2020/06/09/CAP%E7%90%86%E8%AE%BA/"/>
    <id>https://kevll.com/2020/06/09/CAP%E7%90%86%E8%AE%BA/</id>
    <published>2020-06-08T16:00:00.000Z</published>
    <updated>2022-12-19T10:51:53.487Z</updated>
    
    <content type="html"><![CDATA[<p>在如今的互联网应用体系架构中，因系统的庞大和复杂程度，一个系统往往会被拆分为不同的子系统，这样便于水平扩展和解耦。但是同时也增加了整个系统的复杂性，因为不同的子系统通过网络通信，而网络又是不可靠的，如何在这种环境下保证各节点数据备份的一致性；而若干个子系统的崩溃又如何保证整个系统的可用性；这都是一个分布式系统需要考虑和解决的问题。此篇作为分布式入门，讨论一下经典的CAP理论，和一些基础的分布式系统下的概念、问题和解决方案。</p><span id="more"></span><h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><p>在2000年，Eric Brewer在PODC（Principles of Distributed Computing）的研讨会上首次提出了CAP的概念，含义如下：</p><ul><li>C：Consistency，一致性，多个节点在系统运行中是否时刻能保证数据一致的特性。</li><li>A：Availability，可用性，系统必须一直保持可用状态，“可用状态”指的是用户的每一个操作需要在指定的时间内得到反馈，无论成功或失败。</li><li>P：Partition Tolerant，分区容错性，在遇到网络分区故障的时候，整个系统仍然能够保持服务。</li></ul><p>他还提到了一点就是：任何一个分布式系统都无法同时满足CAP中的三个条件，最多只能做到两项。即CA、AP或CP。一般来说分区容错性是个最基本的要求，所以通常在C和P之间寻求平衡。但其实Eric在2012年曾指出这个观点在实际的系统设计指导上有一定的误导性，过于简单化地描述了分布式系统设计中的问题，实际情况要复杂得多，还要看具体需求而定。</p><h2 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h2><p>BASE理论基于CAP演化而来，它的核心思想是：<strong>即使无法达到强一致性，每个应用和业务都应当采取适当的方式来达到最终一致性。</strong>其中BASE的含义如下：</p><ul><li>BA：Basically Available，基本可用，即使有部分系统无法响应，也不影响基本可用性，可以损失一定的响应时间，或是将用户重定向到降级页面。</li><li>S：Soft state，柔性状态，允许不同节点的数据同步存在一定的延迟。</li><li>E：Eventually consistent，最终一致性，所有节点的数据副本在一定时间后都能达到一致的状态。</li></ul><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>分布式环境不同于以往的单机环境，可以使用传统的方法在单进程内对多线程进行管理。由于客户端在不同的机器上，不同的网络环境下，此时对并发情况下资源共享的处理就要用到一些其他的方式来做互斥了，通常我们会借用一些第三方软件来实现一个“分布式锁”，常见的实现方式有如下几种：</p><ul><li>基于数据库：建立锁表，使用表的唯一约束特性实现获取锁的逻辑。</li><li>基于Redis：使用setnx、key-value-UUID方式实现加锁。</li><li>基于Zookeeper：建立资源目录，根据子节点实现资源加锁。</li></ul><h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p>当一个系统被拆分成不同的子系统时，其数据库必定也会被拆分，在这种情况下，如何保证业务的顺利执行呢？也就是如何实现分布式环境下的“事务”，其中有以下实现方案可以提供给我们一点思路：</p><ul><li>2PC：Two phase commit，两阶段提交，第一阶段投票，各节点执行事务，写本地log，但不提交。第二阶段提交，满足所有节点运行正常时进行commit通知，否则全部回滚。</li><li>3PC：Three phase commit，三阶段提交，比两阶段提交多了一个预询盘阶段，该阶段管理者会依此询问各个节点是否可以正常执行事务，是一个很轻量的操作。</li><li>Paxos算法：一种一致性算法。</li></ul><p>2PC保护了数据一致性，在分布式系统设计中有大概三种一致性的区别：</p><ul><li>强一致性：在任意时刻，所有节点的数据都是一致的。</li><li>弱一致性：数据更新后的一段时间里，能接受部分数据访问不了，则为弱一致性。</li><li>最终一致性：不用保证任意时刻数据的一致性，但是随着时间的迁移，各节点的数据会趋向最终一致性。</li></ul><h2 id="柔性事务"><a href="#柔性事务" class="headerlink" title="柔性事务"></a>柔性事务</h2><p>传统事务：ACID，刚性事务，强调强一致性，即同步操作。柔性事务：弱一致性，要达到最终一致性，可以异步操作。总的来说柔性事务是利用相关业务的弹性，找到业务上对于事务过程中的不一致的容忍程度，最后找到时效和功能完整的平衡点。可分为四种不同的柔性事务：</p><ul><li>两阶段型：两阶段提交的典型模式，对应技术上的XA、JTA&#x2F;JTS。</li><li>补偿型：TCC型事务（Try-Confirm-Cancel），一个事务分为AB两个操作，在两台机器上执行。如果A执行顺利，那么就提交，如果B执行顺利也提交顺利了，那么整个事务算完成了。如果B失败了，那么就要对操作A进行补偿，也就是undo操作。</li><li>异步确保型：将一些同步的操作变为异步的，避免对数据库事务的争用，比如批量记账处理。</li><li>最大努力通知型：通过通知服务器进行，允许失败，有补充机制。例如：客户交易结果通知重试、补单重试。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>分布式架构为系统的扩大和拓展提供了方便性，但是也带来了很大的复杂性，如何保证数据的一致性和系统的可用性，都是需要长期研究和探讨的话题。我们需要在业务可以接受的“Soft State”上和数据的一致性时效上做平衡和选择，也要做好各种异常的补偿措施，然后在实际应用中检验成效。</p><p>参考：<br><a href="https://xiaomi-info.github.io/2020/01/02/distributed-transaction/">分布式事务，这一篇就够了</a><br><a href="https://www.zhihu.com/question/31813039">支付宝运营架构中柔性事务指的是什么</a><br><a href="https://zhuanlan.zhihu.com/p/35616810">分布式一致性之两阶段提交协议、三阶提交协议</a><br><a href="https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/">分布式锁的实现之redis篇</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在如今的互联网应用体系架构中，因系统的庞大和复杂程度，一个系统往往会被拆分为不同的子系统，这样便于水平扩展和解耦。但是同时也增加了整个系统的复杂性，因为不同的子系统通过网络通信，而网络又是不可靠的，如何在这种环境下保证各节点数据备份的一致性；而若干个子系统的崩溃又如何保证整个系统的可用性；这都是一个分布式系统需要考虑和解决的问题。此篇作为分布式入门，讨论一下经典的CAP理论，和一些基础的分布式系统下的概念、问题和解决方案。&lt;/p&gt;</summary>
    
    
    
    
    <category term="分布式" scheme="https://kevll.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>理解GC算法与收集器</title>
    <link href="https://kevll.com/2019/10/02/%E7%90%86%E8%A7%A3GC%E7%AE%97%E6%B3%95%E4%B8%8E%E6%94%B6%E9%9B%86%E5%99%A8/"/>
    <id>https://kevll.com/2019/10/02/%E7%90%86%E8%A7%A3GC%E7%AE%97%E6%B3%95%E4%B8%8E%E6%94%B6%E9%9B%86%E5%99%A8/</id>
    <published>2019-10-01T16:00:00.000Z</published>
    <updated>2022-12-19T10:48:02.771Z</updated>
    
    <content type="html"><![CDATA[<p>Java语言最独有的特点之一就是有一套自治的内存管理模型，即JVM（Java Virtual Memory），它帮助我们管理对象的生存周期，所以我们在平时的开发任务中可以专注于功能的具体实现。在JVM有一个称为GC（Garbage Collection）的关键过程，它将会按照一定的规则去整理和清除内存中的对象。本文整理了几种不同的GC算法，学习它们将帮助我们了解当一个Java程序运行起来的时候，JVM到底是怎样管理内存的。<span id="more"></span></p><blockquote><p>Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人却想出来。  – 《深入理解JVM》</p></blockquote><p>JVM运行起来的时候，其内存主要分为6个部分，其中堆（Heap）是JVM存储大量对象的一块共享的内存，也是占比最大的一块区域，GC的主要工作就是对这块内存进行管理。如下图所示：<br><img src="/images/191002_runtime_areas.png" alt="图1：运行时数据区域"></p><h2 id="哪些对象需要回收"><a href="#哪些对象需要回收" class="headerlink" title="哪些对象需要回收"></a>哪些对象需要回收</h2><p>JVM如何判断一个对象是否需要被回收？主流的实现是通过一个叫可达性分析的方法来判定的，JVM会定义一系列的“GC Roots”，包含以下几种：</p><ul><li>虚拟机栈中引用的对象</li><li>方法区中类静态属性引用的对象</li><li>方法区中常亮引用的对象</li><li>本地方法栈JNI（Native方法）引用的对象</li></ul><p>从这些Roots开始向下搜索，走过的路程称为引用链，如果一个对象找不到一条引用链来与Roots相连的话，那它就将被第一次标记。确认需要被回收需要两次标记，第二次则是在一个称为F-Queue的队列中，JVM将会执行对象的finalize方法，如果方法执行完后该对象还是没有与GC Roots相连，则会被第二次标记，等待GC的回收（finalize方法在jdk9中已被置为Deprecated）。当GC开始工作的时候，这些可以被回收的对象就会按照一定规则被清理掉了，以下是常用的四种GC算法：</p><h3 id="1-标记清除（Mark-Sweep）"><a href="#1-标记清除（Mark-Sweep）" class="headerlink" title="1.标记清除（Mark-Sweep）"></a>1.标记清除（Mark-Sweep）</h3><p>标记清除是最基本的一种GC算法，首先就是标记好需要清理的对象，上文已经阐述过，紧接着第二步就是要把它们所占的内存清理掉。这个算法主要的问题就是在清除过后会留下大量不连续的内存空间，不利于在之后的程序中分配比较大的对象。</p><h3 id="2-复制（Copying）"><a href="#2-复制（Copying）" class="headerlink" title="2.复制（Copying）"></a>2.复制（Copying）</h3><p>复制算法将JVM的内存切分为两个同样大的部分，程序使用的时候只使用其中的一个，当需要GC的时候，就把使用中的那一半内存里的存活对象复制到另一半内存，并且按顺序排列。它解决了内存碎片的问题，但是能使用的内存空间被减少了一半，代价过高。</p><h4 id="复制算法在新生代的使用"><a href="#复制算法在新生代的使用" class="headerlink" title="复制算法在新生代的使用"></a>复制算法在新生代的使用</h4><p>现在大部分虚拟机都用复制算法回收新生代，因为新生代的存活率并不高，所以实际上内存不是对半划分的，内存会被分为一块较大的Eden空间和两块较小的Survivor空间，他们的比率是8:1，每次使用Eden和其中一块Survivor来存放对象，当发生GC的时候就把存活下来的对象拷贝到另一个Survivor中，如此反复。</p><h3 id="3-标记整理（Mark-Compact）"><a href="#3-标记整理（Mark-Compact）" class="headerlink" title="3.标记整理（Mark-Compact）"></a>3.标记整理（Mark-Compact）</h3><p>标记整理类似于标记清除，不同的是所有的存活对象会被重新整理，重新占连续的内存，以便清除内存碎片。</p><h3 id="4-分代收集（Generational-Collection）"><a href="#4-分代收集（Generational-Collection）" class="headerlink" title="4.分代收集（Generational Collection）"></a>4.分代收集（Generational Collection）</h3><p>分代收集主要是将内存分为了新生代和老年代，并且结合了前面几种GC算法，在不同的代区中使用不同的算法。例如在新生代，由于一般情况下90%以上的新对象都不会持久，所以使用复制算法，只需要复制一小部分的存活对象即可。而因为老年代里，对象存活率比较高则使用标记清理或标记整理的算法来清除。</p><h2 id="收集器"><a href="#收集器" class="headerlink" title="收集器"></a>收集器</h2><p>收集器就是结合这些GC算法的具体实现了，没有万能的收集器，只有在不同的场景下使用合适的收集器。以下讨论的收集器是基于JDK1.7Update14之后的HotSpot虚拟机，如下图所示：（有连线的表示可以搭配使用）<br><img src="/images/191002_hotspot_collectors.png" alt="图2：HotSpot的收集器"></p><h3 id="1-Serial收集器"><a href="#1-Serial收集器" class="headerlink" title="1.Serial收集器"></a>1.Serial收集器</h3><p>Serial收集器是最基本的一款收集器，它是单线程工作的，而且工作的时候需要暂停所有的其它的用户线程，直到收集完毕。它的优势是简单有效，但是Stop The World时间太长不太友好，对于单个CPU以Client模式运行的虚拟机是个不错的选择。</p><h3 id="2-ParNew收集器"><a href="#2-ParNew收集器" class="headerlink" title="2.ParNew收集器"></a>2.ParNew收集器</h3><p>ParNew是Serial的多线程版本，在新生代中只有它和Serial能与老年代的CMS收集器搭配使用。</p><h3 id="3-Parallel-Scavenge收集器"><a href="#3-Parallel-Scavenge收集器" class="headerlink" title="3.Parallel Scavenge收集器"></a>3.Parallel Scavenge收集器</h3><p>Parallel Scavenge是一个关注吞吐量的收集器，吞吐量指的是：用户线程的执行时间&#x2F;(用户线程的执行时间+GC时间)。它提供自定义设置来动态控制吞吐量，例如要是关注GC停顿时间的话，使用-XX:MaxGCPauseMillis去控制GC停顿的最大时间，这个时候新生代空间将会缩小，相对的GC的频率也会变高点。要是关注吞吐量，则可以使用-XX:GCTimtRatio来直接控制最大吞吐量，虚拟机会根据当前系统信息动态调整状态以趋近于这个吞吐量。</p><h3 id="4-Serial-Old收集器"><a href="#4-Serial-Old收集器" class="headerlink" title="4.Serial Old收集器"></a>4.Serial Old收集器</h3><p>Serial Old是Serial的老年代版本，它可以与Parallel Scavenge搭配使用，或作为CMS的后背预案。</p><h3 id="5-Parallel-Old收集器"><a href="#5-Parallel-Old收集器" class="headerlink" title="5.Parallel Old收集器"></a>5.Parallel Old收集器</h3><p>Parallel Old是Parallel Scavenge的老年代版本，在JDK1.6开始提供，之后在注重吞吐量或CPU资源敏感的场合都可以直接选取这两种搭配了。</p><h3 id="6-CMS收集器"><a href="#6-CMS收集器" class="headerlink" title="6.CMS收集器"></a>6.CMS收集器</h3><p>CMS（Concurrent Mark Sweep）的特点是：并发收集、低停顿，也可称为低停顿收集器（Concurrent Low Pause Collector）。</p><h3 id="7-G1收集器"><a href="#7-G1收集器" class="headerlink" title="7.G1收集器"></a>7.G1收集器</h3><p>G1是目前最前沿的一款收集器，被视为JDK1.7中HotSpot的一个重要的进化特征。G1将整个Java堆划分为多个大小相同的区域，它跟踪每个区域里面的垃圾堆积的价值大小，每次根据允许的收集时间，优先回收价值最大的区域。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Java语言最独有的特点之一就是有一套自治的内存管理模型，即JVM（Java Virtual Memory），它帮助我们管理对象的生存周期，所以我们在平时的开发任务中可以专注于功能的具体实现。在JVM有一个称为GC（Garbage Collection）的关键过程，它将会按照一定的规则去整理和清除内存中的对象。本文整理了几种不同的GC算法，学习它们将帮助我们了解当一个Java程序运行起来的时候，JVM到底是怎样管理内存的。</summary>
    
    
    
    
    <category term="JVM" scheme="https://kevll.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>事务的ACID及其实现</title>
    <link href="https://kevll.com/2019/09/16/%E4%BA%8B%E5%8A%A1%E7%9A%84ACID%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/"/>
    <id>https://kevll.com/2019/09/16/%E4%BA%8B%E5%8A%A1%E7%9A%84ACID%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/</id>
    <published>2019-09-15T16:00:00.000Z</published>
    <updated>2022-01-18T10:26:49.163Z</updated>
    
    <content type="html"><![CDATA[<p>在软件开发中，后端的实质就是操作数据，储存数据，那就要与各种数据库打交道。在数据库中，为了保证数据的一致性，规定了一个“事务”的概念，它是一系列数据库操作的集合。ACID是事务的四个重要的特性，理解这四个特性及它们的实现原理可以在一定程度上理解数据库到底是怎样工作的。<span id="more"></span></p><h2 id="Atomicity-原子性"><a href="#Atomicity-原子性" class="headerlink" title="Atomicity(原子性)"></a>Atomicity(原子性)</h2><blockquote><p>在一个事务中的若干个数据库操作，要么全部执行成功，要么全部不执行。任何时候，事务为一个整体，是一个不可被打断的一个操作集合。</p></blockquote><p>在一个事务的执行中，如果遇到异常，则需要进行一种叫做“回滚”的操作，它会对已经执行过的操作进行回滚，从而保证数据回到这一系列操作集合都没有被执行的状态。Mysql中，所有的数据库操作都会先被记录到一个回滚日志(undo log)中，然后再将数据写入磁盘。这个回滚日志是一个逻辑日志，对应着实际修改语句的反向操作，例如insert语句对应的就是delete语句，update语句对应一条相反的update。这样在程序发现异常的时候，数据库就可以执行这些语句，尝试将数据恢复到事务执行之前的样子，从而保证事务操作的原子性。<br>值得注意的是，事务只能保证对数据库操作的原子性，如果在事务中有其它的操作，例如向其它系统发送一条消息、向用户发送邮件，这些都是无法再撤销的，需要开发者去解决这些问题。（我自身就处理过这样的问题，当时要在事务结束的时候发送一条扣款的MQ，但是当程序发生异常需要回滚的时候，这条发出去的消息就无法撤销了。所以要将这个操作放在最后执行，尽量也要放在事务之外，防止消费者在操作这条消息的时候拿到的是前者事务还未提交的数据。</p><h2 id="Durability-持久性"><a href="#Durability-持久性" class="headerlink" title="Durability(持久性)"></a>Durability(持久性)</h2><blockquote><p>事务被提交后，需要保证被改变数据的持久性，即使数据库出现故障，例如宕机或停电都不会受影响。</p></blockquote><p>事务的持久性也是通过日志来实现，Mysql中用重做日志(redo log)记录了一个事务内的所有数据库操作。这些操作会先被记到日志中，然后将改变写入数据库。日志也是记在硬盘上的，在发生错误时，数据库可以重新从重做日志中找到相应的信息来继续执行操作，从而保证事务的持久性。</p><h2 id="Isolation-隔离性"><a href="#Isolation-隔离性" class="headerlink" title="Isolation(隔离性)"></a>Isolation(隔离性)</h2><blockquote><p>并发访问数据库的时候，一个事务的操作不受其它的事务影响，并发的多个事务间保持相互独立。</p></blockquote><p>在实际的情况下，对数据的访问不会是串行的，通常是多个线程或者多个进程同时访问同一行数据。那么这个时候谁拿到什么样的数据，就是数据库要进行控制的内容，这也是一个比较复杂的内容，因为涉及到了并发和数据一致性的问题。数据库实现了几种并发情况下对数据库访问的规则，分为了四个不同的级别，它们称为事务的隔离级别。它们是：</p><ol><li>Read Uncommited</li><li>Read Commited</li><li>Repeatable Read</li><li>Serialize</li></ol><p>需要注意的是，随着隔离级别越来越高，数据库处理并发事务的性能也越来越低，到了最后的Serialize就是把所有的并行操作当作串行来操作了。这些隔离级别并不能保证你读到的数据就是对的，它只是确定了在并发的情况下以怎样的方式去读取数据。隔离级别的实现就是使用并发控制，这里介绍两种常见的实现：</p><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>数据库一般有两种锁，共享锁和互斥锁，又称为读锁和写锁。共享锁是相互兼容的，它允许多个事务进行并发的读操作，而互斥锁顾名思义，是相互排斥的，同一时刻只能有一个事务拿到这把锁。从而实现并行读，串行写的数据操作效果。</p><h3 id="多版本"><a href="#多版本" class="headerlink" title="多版本"></a>多版本</h3><p>在Mysql中有一个叫MVCC的的实现，其中官方文档描述如下：</p><blockquote><p>Acronym for “multiversion concurrency control”. This technique lets InnoDB transactions with certain isolation levels perform consistent read operations; that is, to query rows that are being updated by other transactions, and see the values from before those updates occurred. This is a powerful technique to increase concurrency, by allowing queries to proceed without waiting due to locks held by the other transactions.<br>This technique is not universal in the database world. Some other database products, and some other MySQL storage engines, do not support it.</p></blockquote><p>文中意思就是这个称为“多版本并发控制”的机制，可以在特定隔离级别下保证事务一致性地去读取数据。就是查询正在被其它事务更新的数据的原始值，这样增强了数据库的并发事务的处理能力，查询操作不需要等待其它事务释放锁。</p><h2 id="Consistency-一致性"><a href="#Consistency-一致性" class="headerlink" title="Consistency(一致性)"></a>Consistency(一致性)</h2><blockquote><p>事务的一致性是一个比较特殊的属性，它需要数据库和开发者来共同实现。在事务执行的前后，数据从一个正确的状态迁移至另一个正确的状态。其中正确的状态指的是数据本身的约束及应用层的约束保持不被破坏。</p></blockquote><h3 id="数据本身的约束："><a href="#数据本身的约束：" class="headerlink" title="数据本身的约束："></a>数据本身的约束：</h3><p>数据本身应当保证正确性，例如不可被改变为其它类型，不可破坏主键约束，不可破坏唯一性以及其它在表设计完后已经规定好的约束。</p><h3 id="应用层的约束："><a href="#应用层的约束：" class="headerlink" title="应用层的约束："></a>应用层的约束：</h3><p>例如在表中有余额字段，其应用层的正确性，或者说是业务层的正确性就是该值不能小于0，如果该字段在数据库中没有不小于0的约束的话，这个数据的正确性只能由开发者保证。</p><blockquote><p>在事务执行的时候，也要保证别的事务读取数据的正确性和一致性，也就是事务操作数据的中间状态对其它事务不可见。</p></blockquote><p>参考：<br><a href="https://draveness.me/mysql-transaction">『浅入深出』MySQL 中事务的实现</a><br><a href="https://dev.mysql.com/doc/refman/5.5/en/glossary.html">Mysql术语表</a><br><a href="https://www.zhihu.com/question/31346392">如何理解数据库事务中的一致性的概念？</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在软件开发中，后端的实质就是操作数据，储存数据，那就要与各种数据库打交道。在数据库中，为了保证数据的一致性，规定了一个“事务”的概念，它是一系列数据库操作的集合。ACID是事务的四个重要的特性，理解这四个特性及它们的实现原理可以在一定程度上理解数据库到底是怎样工作的。</summary>
    
    
    
    
    <category term="数据库" scheme="https://kevll.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>理解工厂模式</title>
    <link href="https://kevll.com/2019/08/04/%E7%90%86%E8%A7%A3%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
    <id>https://kevll.com/2019/08/04/%E7%90%86%E8%A7%A3%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</id>
    <published>2019-08-03T16:00:00.000Z</published>
    <updated>2022-03-13T10:15:42.703Z</updated>
    
    <content type="html"><![CDATA[<p>工厂设计模式是众多设计模式当中我最早接触的设计模式，也是一种应用最为广泛的设计模式，属于创建型设计模式。在Spring框架中，也有很经典的应用。在我对其进行了解的时候，发现有几种不同的工厂模式，本文对这几种工厂模式之间的差别进行一下分析和解读。<span id="more"></span></p><p>工厂模式的产生，是为了降低代码耦合，统一管理产品，提高工作效率。</p><h3 id="四种常见的工厂模式"><a href="#四种常见的工厂模式" class="headerlink" title="四种常见的工厂模式"></a>四种常见的工厂模式</h3><ol><li>StaticFactory Method - 静态工厂方法</li><li>SimpleFactory - 简单工厂</li><li>Factory Method - 工厂方法</li><li>Abstract Factory - 抽象工厂模式</li></ol><h4 id="StaticFactory-Method"><a href="#StaticFactory-Method" class="headerlink" title="StaticFactory Method"></a>StaticFactory Method</h4><p>相对于构造器来说，静态工厂有如下优势：</p><ul><li>方法名称不是固定的，可以自定义有意义的方法名称</li><li>返回值可以是原类型、子类型或是原始类型</li><li>可以控制类的实例，单例模式就是一种很好的应用</li></ul><p>静态工厂在jdk中也有使用，例如String、Integer、Long、Optional、Collections等包含的一系列静态工厂方法：</p><ul><li>String.valueOf(1000L);</li><li>Integer.valueOf(“180”);</li><li>Long.valueOf(“9999”);</li><li>Optional.of(“value”);</li><li>Collections.synchronizedCollection(originalCollection);</li></ul><h4 id="Simple-Factory"><a href="#Simple-Factory" class="headerlink" title="Simple Factory"></a>Simple Factory</h4><p>简单工厂模式，有一个专门的工厂类，可以根据参数去生产特定的产品，它不属于23GOF。例如下面的一个电脑工厂：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public class SimpleFactory &#123;</span><br><span class="line"></span><br><span class="line">    public static final int HP = 1;</span><br><span class="line">    public static final int LENOVO = 2;</span><br><span class="line">    public static final int APPLE = 3;</span><br><span class="line"></span><br><span class="line">    public static Computer createComputer(int param) &#123;</span><br><span class="line">        switch (param) &#123;</span><br><span class="line">            case HP:</span><br><span class="line">                return new HpComputer();</span><br><span class="line">            case LENOVO:</span><br><span class="line">                return new LenovoComputer();</span><br><span class="line">            case APPLE:</span><br><span class="line">                return new AppleComputer();</span><br><span class="line">            default:</span><br><span class="line">                return null;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Factory-Method"><a href="#Factory-Method" class="headerlink" title="Factory Method"></a>Factory Method</h4><p>工厂模式有一个工厂父类，提供了生产电脑的接口，各个厂牌的工厂可以去继承并实现它，完成自己的生产逻辑：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">// 父类工厂</span><br><span class="line">public interface ComputerFactory &#123;</span><br><span class="line"></span><br><span class="line">    Computer createComputer();</span><br><span class="line">&#125;</span><br><span class="line">// 惠普工厂实现</span><br><span class="line">public class HpComputerFactory implements ComputerFactory &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Computer createComputer() &#123;</span><br><span class="line">        return new HpComputer();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">// 联想工厂实现</span><br><span class="line">public class LenovoComputerFactory implements ComputerFactory &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Computer createComputer() &#123;</span><br><span class="line">        return new LenovoComputer();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Abstract-Factory"><a href="#Abstract-Factory" class="headerlink" title="Abstract Factory"></a>Abstract Factory</h4><p>到了抽象工厂，就要提到产品簇（Product Family）的概念。产品簇指的是具有相似功能的一系列产品，它们通常需要聚合或是搭配着来完成一项功能。例如上面的电脑产品，其可以被拆分为主机、屏幕、键盘、鼠标、耳机等等。这些拆分的部件通常也不是在一个工厂完成生产，而且也不一定都和自己的厂牌结合使用。厂牌下的各个子产品的生产逻辑抽象出来产生了抽象工厂这种设计方法。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">// 父类产品工厂</span><br><span class="line">public interface ComputerProductFactory &#123;</span><br><span class="line"></span><br><span class="line">    Keyboard createKeyboard();</span><br><span class="line"></span><br><span class="line">    Mouse createMouse();</span><br><span class="line"></span><br><span class="line">    Earphone createEarphone();</span><br><span class="line">&#125;</span><br><span class="line">// 惠普产品工厂实现</span><br><span class="line">public class HpProductFactory implements ComputerProductFactory &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public Keyboard createKeyboard() &#123;</span><br><span class="line">        return new HpKeyboard();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Mouse createMouse() &#123;</span><br><span class="line">        return new HpMouse();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Earphone createEarphone() &#123;</span><br><span class="line">        return new HpEarphone();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">// 联想产品工厂实现</span><br><span class="line">public class LenovoProductFactory implements ComputerProductFactory &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public Keyboard createKeyboard() &#123;</span><br><span class="line">        return new LenovoKeyboard();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Mouse createMouse() &#123;</span><br><span class="line">        return new LenovoMouse();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Earphone createEarphone() &#123;</span><br><span class="line">        return new LenovoEarphone();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>产品簇指具有相同或相似的功能结构或性能，共享主要的产品特征、组件或子结构，并通过变型配置来满足特定市场的一组产品的聚类。其背景是一个规划精良的结构，即可以用来生成产品族的产品族概念结构和总体逻辑结构，有助于把握和利用产品的共性。每一个新产品都是该结构的具体实例，也是对结构的扩展。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;工厂设计模式是众多设计模式当中我最早接触的设计模式，也是一种应用最为广泛的设计模式，属于创建型设计模式。在Spring框架中，也有很经典的应用。在我对其进行了解的时候，发现有几种不同的工厂模式，本文对这几种工厂模式之间的差别进行一下分析和解读。</summary>
    
    
    
    
    <category term="设计模式" scheme="https://kevll.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>编程语言的类别</title>
    <link href="https://kevll.com/2019/04/09/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E7%B1%BB%E5%88%AB/"/>
    <id>https://kevll.com/2019/04/09/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E7%B1%BB%E5%88%AB/</id>
    <published>2019-04-08T16:00:00.000Z</published>
    <updated>2022-12-19T10:53:37.281Z</updated>
    
    <content type="html"><![CDATA[<p>目前的工作中，已经学习到了三种语言，Java，JS，Python。在说到这些语言时，经常会听到别人对它们的不同称呼，例如说Java是静态语言；Python、JS是脚本语言；Java是强类型而Python、JS是弱类型；Python、JS是解释型语言等。很好奇这些分类到底是怎么划分的，在查阅相关资料后对这些语言类别做了一些整理和归纳。<span id="more"></span></p><p>其实看了一些文章后才知道，这些语言的类型划分并不存在一个严格的定义，大多都是众人口传口的一种说法。所以下文的分析也只能保持一定程度的参考性，只为了更好的理解语言之间的区别。</p><h2 id="编译型语言、解释型语言"><a href="#编译型语言、解释型语言" class="headerlink" title="编译型语言、解释型语言"></a>编译型语言、解释型语言</h2><p><strong>编译或解释不是语言的特性，而是实现的特性。</strong> 所以广义上的编译和解释的区分，在于语言偏向用哪一种方式实现。所以如果你写了一个C语言的解释器的话，也可以让C直接解释执行了。在R大的这篇<a href="https://rednaxelafx.iteye.com/blog/492667">文章</a>中可以看到编译与解释在一定程度上的区别：采用编译和解释方式实现虚拟机最大的区别就在于是否存下目标代码：编译的话会把输入的源程序以某种单位（例如基本块&#x2F;函数&#x2F;方法&#x2F;trace等）翻译生成为目标代码，并存下来（无论是存在内存中还是磁盘上，无所谓），后续执行可以复用之；解释的话则是把源程序中的指令逐条解释，不生成也不存下目标代码，后续执行没有多少可复用的信息。</p><h2 id="静态语言、动态语言"><a href="#静态语言、动态语言" class="headerlink" title="静态语言、动态语言"></a>静态语言、动态语言</h2><p>动态语言在运行时进行类型检查，在编写代码的时候可以不指定变量的数据类型，比如Python、JS。而静态语言例如C、Java，它们的数据类型是在编译期确定的，所在声明变量的同时要显式地写清数据类型，这样的好处是可以提前检查出程序中可能出现的类型错误。</p><h2 id="强类型、弱类型"><a href="#强类型、弱类型" class="headerlink" title="强类型、弱类型"></a>强类型、弱类型</h2><p>强弱类型指的是语言的类型系统对类型检查的严格程度。弱类型允许变量类型的隐式转化，而强类型一般不允许这样做。其实这也是和语言的主流编译器有关系的，Python被称为强类型，因为CPython在运行期检测到类型错误时，程序会中断执行。</p><h2 id="脚本语言"><a href="#脚本语言" class="headerlink" title="脚本语言"></a>脚本语言</h2><p>脚本语言也是一个常常听到的名词。它给我的感觉就是方便快捷，不一定像一门编程语言一样有复杂的设计、严谨的语法和规则。例如我们在Linux中为了自动化部署程序写的shell脚本，在windows里执行批任务的vbs脚本。脚本语言是最松散的类型定义，完全没有类型声明，并且在运行时进行动态类型检查。脚本语言可以是交互式的，这样完全将编译过程从编辑-编译-运行循环中去掉了。脚本语言在易用性的优势让它的执行速度比系统语言慢了很多。它的代码可以以源代码的方式发布执行，虽然Python也有编译的步骤，但大多数情况直接接受源代码，而不是编译后的文件。</p><p>参考：<br><a href="https://www.zhihu.com/question/19918532">知乎-弱类型、强类型、动态类型、静态类型语言的区别是什么？</a><br><a href="https://rednaxelafx.iteye.com/blog/492667">RednaxelaFX-虚拟机随谈（一）：解释器，树遍历解释器，基于栈与基于寄存器，大杂烩</a><br><a href="https://www.zhihu.com/question/19608553">知乎-Java 是编译型语言还是解释型语言？</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;目前的工作中，已经学习到了三种语言，Java，JS，Python。在说到这些语言时，经常会听到别人对它们的不同称呼，例如说Java是静态语言；Python、JS是脚本语言；Java是强类型而Python、JS是弱类型；Python、JS是解释型语言等。很好奇这些分类到底是怎么划分的，在查阅相关资料后对这些语言类别做了一些整理和归纳。</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>关键字synchronized</title>
    <link href="https://kevll.com/2018/11/05/%E5%85%B3%E9%94%AE%E5%AD%97synchronized/"/>
    <id>https://kevll.com/2018/11/05/%E5%85%B3%E9%94%AE%E5%AD%97synchronized/</id>
    <published>2018-11-04T16:00:00.000Z</published>
    <updated>2022-12-19T10:53:52.202Z</updated>
    
    <content type="html"><![CDATA[<p>synchronized是Java中用来处理多线程的字段，也是我刚开始接触多线程时碰到的字眼，此篇记录下关于synchronized的一些理解和学习记录。<span id="more"></span></p><h3 id="synchronized是什么？"><a href="#synchronized是什么？" class="headerlink" title="synchronized是什么？"></a>synchronized是什么？</h3><p>synchronized是Java语法中的一个关键字，它可以作用在方法体和代码块上。这个关键字在被编译之后，会形成monitorenter和monitorexit两个字节码指令。这两个指令表示同步块的进入和退出，执行monitorenter时，线程尝试去获取锁的对象，如果获取成功，锁计数+1；执行到monitorexit时，锁计数-1，锁被释放。另一种说法就是sychronized就是JVM的这两个字节码指令暴露给程序员使用的接口。</p><h3 id="synchronized修饰方法与代码块的区别"><a href="#synchronized修饰方法与代码块的区别" class="headerlink" title="synchronized修饰方法与代码块的区别"></a>synchronized修饰方法与代码块的区别</h3><p>synchronized在修饰代码块时，会传递一个锁参数，如果这个参数是this的话，那同步代码块和同步方法也没什么区别。这种也叫做静态同步，它锁定的是类。另一种为非静态同步，锁定的是类的实例。在以实例为锁的情况下，在使用同一实例的时候就只能有一个线程可以进入同步块。</p><h3 id="synchronized与Lock的区别"><a href="#synchronized与Lock的区别" class="headerlink" title="synchronized与Lock的区别"></a>synchronized与Lock的区别</h3><ol><li>Lock是一个接口，而synchronized是java的一个关键字，synchronized是内置的语言实现，Lock底层由volatile和CAS实现</li><li>synchronized在发生异常时候会自动释放占有的锁，因此不会出现死锁；而lock发生异常时候，不会主动释放占有的锁，必须手动unlock来释放锁，可能引起死锁的发生。（所以最好将同步代码块用try catch包起来，finally中写入unlock，避免死锁的发生。） </li><li>Lock等待锁过程中可以用interrupt来中断等待，而synchronized只能等待锁的释放，不能响应中断； </li><li>Lock可以通过trylock来知道有没有获取锁，而synchronized不能； </li><li>Lock可以提高多个线程进行读操作的效率。（可以通过readwritelock实现读写分离）</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;synchronized是Java中用来处理多线程的字段，也是我刚开始接触多线程时碰到的字眼，此篇记录下关于synchronized的一些理解和学习记录。</summary>
    
    
    
    
    <category term="并发" scheme="https://kevll.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>理解数据库事务</title>
    <link href="https://kevll.com/2018/10/20/%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/"/>
    <id>https://kevll.com/2018/10/20/%E7%90%86%E8%A7%A3%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/</id>
    <published>2018-10-19T16:00:00.000Z</published>
    <updated>2022-01-18T10:26:49.171Z</updated>
    
    <content type="html"><![CDATA[<p>事务是数据库提供的一种功能，为了保证数据操作的安全性。在数据库中，一个事务可以是一条语句，也可以是多条语句的联合。事务应该具有4个属性：原子性、一致性、隔离性、持续性。这四个属性通常称为ACID特性。<span id="more"></span></p><h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><ol><li>读未提交 Read Uncommitted：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。</li><li>读提交 Read Committed：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。</li><li>可重复读 Repeatable Read： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。</li><li>序列化 Serializable：所有事物串行处理（牺牲了效率）</li></ol><h3 id="脏读"><a href="#脏读" class="headerlink" title="脏读"></a>脏读</h3><p>如果一个事务中对数据进行了更新，但事务还没有提交，另一个事务可以“看到”该事务没有提交的更新结果，这样造成的问题就是，如果第一个事务回滚，那么，第二个事务在此之前所“看到”的数据就是一笔脏数据。</p><h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p>同一个事务在整个事务过程中对同一笔数据进行读取，每次读取结果都不同。如果事务1在事务2的更新操作之前读取一次数据，在事务2的更新操作之后再读取同一笔数据一次，两次结果是不同的，所以，Read Uncommitted也无法避免不可重复读取的问题。不可重复读的重点是修改:同样的条件, 你读取过的数据, 再次读取出来发现值不一样了幻读：（针对其他提交前后，读取数据条数的对比） </p><h3 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h3><p>同样一笔查询在整个事务过程中多次执行后，查询所得的结果集是不一样的。幻读针对的是多笔记录。幻读的重点在于新增或者删除 (数据条数变化)同样的条件, 第1次和第2次读出来的记录数不一样事务的传播行为所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。</p><h2 id="事务的传播行为"><a href="#事务的传播行为" class="headerlink" title="事务的传播行为"></a>事务的传播行为</h2><ol><li>REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。</li><li>SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。</li><li>MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。</li><li>REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。</li><li>NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。</li><li>NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。</li><li>NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于REQUIRED。</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;事务是数据库提供的一种功能，为了保证数据操作的安全性。在数据库中，一个事务可以是一条语句，也可以是多条语句的联合。事务应该具有4个属性：原子性、一致性、隔离性、持续性。这四个属性通常称为ACID特性。</summary>
    
    
    
    
    <category term="数据库" scheme="https://kevll.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>线程安全的级别与实现</title>
    <link href="https://kevll.com/2018/07/18/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E7%BA%A7%E5%88%AB%E4%B8%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>https://kevll.com/2018/07/18/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E7%BA%A7%E5%88%AB%E4%B8%8E%E5%AE%9E%E7%8E%B0/</id>
    <published>2018-07-17T16:00:00.000Z</published>
    <updated>2022-01-18T10:26:49.172Z</updated>
    
    <content type="html"><![CDATA[<p>在之前的理解中，以为一个类要么是线程安全的，要么是不安全的，但其实这里面还有细分和区别。此篇讨论一下多线程的不同安全级别，以及操作系统和程序是如何来实现线程安全的。<span id="more"></span></p><h2 id="安全级别"><a href="#安全级别" class="headerlink" title="安全级别"></a>安全级别</h2><p>在《深入JVM》一书中，按照线程安全的“安全程度”由强到弱可以分为以下5个级别：</p><ol><li><p>不可变<br>在Java中，不可变的对象一定是线程安全的，在使用的时候不需要任何额外的手段来保证线程安全。如果是基本数据类型，那么在定义的时候加上final关键字就可以保证它是不可变的，如果是对象，那么要保证对象的行为不会对自身的状态产生影响。例如String就是一个典型的不可变对象，它所有的操作方法都是返回一个新的对象而不改变原来的值。因为String是不可变的，所以在常量池里的字符串对象可以被所有的线程共享而不存在安全性的问题。</p></li><li><p>绝对线程安全<br>“绝对”的线程安全其实是一种很严格的定义，我们平时常说的线程安全大多都不是绝对的线程安全。如果一个类要达到绝对线程安全，那么就是说不管在什么情况下，都不需要额外的手段来保障线程安全。来看一个例子，一个线程安全的类在多线程下的操作依然产生异常：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public class VectorTest &#123;</span><br><span class="line">    /**</span><br><span class="line">     * Vector不是绝对的线程安全</span><br><span class="line">     */</span><br><span class="line"></span><br><span class="line">    private static Vector&lt;Integer&gt; vector=new Vector&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        while(true)&#123;</span><br><span class="line">            for (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">                vector.add(i);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            Thread removeThread=new Thread()&#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    for (int i = 0; i &lt; vector.size(); i++) &#123;</span><br><span class="line">                        vector.remove(i);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line"></span><br><span class="line">            Thread printThread=new Thread()&#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    for (int i = 0; i &lt; vector.size(); i++) &#123;</span><br><span class="line">                        vector.get(i);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line"></span><br><span class="line">            removeThread.start();</span><br><span class="line">            printThread.start();</span><br><span class="line"></span><br><span class="line">            while(Thread.activeCount()&gt;20);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>例子会抛出以下异常：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;Thread-1497&quot; java.lang.ArrayIndexOutOfBoundsException: Array index out of range: 26</span><br><span class="line">at java.util.Vector.get(Vector.java:748)</span><br><span class="line">at com.kevll.temp.VectorTest$2.run(VectorTest.java:36)</span><br></pre></td></tr></table></figure><p>我们都知道Vector的add()，remove()，get()方法都是被synchronize修饰的，但是这样并不能保证在任何情况下调用它们都是线程安全的。确实如果单独调用remove()或是单独get()是不会报错的，但是同时使用的时候我们必须手动在程序中为这两个方法加上互斥，这样才能保证线程安全。此时，因为有了额外手段地加入，所以它并不是绝对地线程安全了。</p></li><li><p>相对线程安全<br>相对线程安全就是我们通常说的线程安全，它保证了对象地单独操作是安全的，Java中声明线程安全的类都是相对线程安全的，例如Vector和HashTable等。</p></li><li><p>线程兼容<br>线程兼容指的是对象本身不是线程安全的，但是可以通过额外的手段达到线程安全，Java中的大多数类都属于这种。</p></li><li><p>线程对立<br>线程对立是无论采用什么措施都不能在多线程下保证安全使用的代码。</p></li></ol><h2 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h2><p>实现“线程”主要有3种方式：</p><ol><li><p>使用内核线程实现<br>内核线程是直接由操作系统支持和进行调度和切换的线程，但是程序一般使用的是内核线程的另一种接口：轻量级进程（Light Weight Process, LWP），就是我们通常说的线程，系统只有支持了内核线程才有轻量级进程。但是轻量级进程还是基于内核线程实现的，每次线程的操作都会消耗一定的内核资源，系统级的调用代价相对较高，需要在用户态和内核态之间来回切换。而且一个系统支持的轻量级进程的数量也是有限的。</p></li><li><p>使用用户线程实现<br>用户线程则是完全建立在用户空间的线程库上，线程的操作都在用户态中完成，不需要去调用内核。这种线程操作速度快、消耗低，所以支持更大规模的线程数量。但是此时线程的调度和切换的问题都要有用户程序来自己控制，复杂度较大，在处理多核间线程和阻塞的问题上就比较难以实现了。现在仅仅使用用户线程的程序越来越少，Java、Ruby等语言曾经使用过，后来抛弃了。</p></li><li><p>使用用户线程加轻量级进程混合实现<br>这种方式下，用户线程和轻量级进程同时存在，有了用户线程高效廉价和对大规模线程数量的支持，又可以通过轻量级进程与系统内核进行交互，是大多数程序采用的线程实现方式。</p></li></ol><p>Java线程的实现：<br>在jdk1.2之前，Java线程基于用户线程实现，之后采用基于操作系统原生线程模型来实现。</p><h3 id="线程安全的实现"><a href="#线程安全的实现" class="headerlink" title="线程安全的实现"></a>线程安全的实现</h3><p>实现线程安全主要有3种方式，其下有又有多种实现方式：</p><ol><li><p>互斥同步<br>保证共享数据在同一时刻只被一个线程使用。在Java中，提供了synchronized关键字可以实现互斥同步，它其实是monitorenter和monitorexit字节码指令对使用者开放的接口。synchronized是一种重量级的操作，前面说过Java线程是基于操作系统的原生线程，这是对线程的阻塞或唤醒操作都要在用户态和核心态之间切换。在jdk1.5的并发包之后，还可以使用ReentrantLock来实现同步，它是API层的互斥锁，而synchronized为原生语法层面的互斥锁。</p></li><li><p>非阻塞同步<br>上面的互斥同步也可称为阻塞同步，不管会不会发生冲突，直接对方法加锁，挂起线程以避免冲突。而非阻塞同步是不挂起线程，直接进行操作，遇到冲突再解决。这种同步需要保证操作和冲突检测这两个步骤的原子性，这有依赖于“硬件指令集的发展”。</p></li><li><p>无同步方案<br>我们要保证线程安全，才采用了同步这种手段，而如果一个方法不涉及数据共享或是代码本身就是线程安全的，则不需要采用同步，例如可重入代码和线程本地存储。</p></li></ol><ul><li><p>可重入代码：<br>这种代码有些相同的特性，它们不依赖存储在堆上的数据或是公用的系统资源，不调用非可重入的方法。也可以通过以下原则来判定：如果一个方法的结果可以预测，就是说每个给定参数都能返回相同的结果，那么它就是可重入的，是线程安全的。</p></li><li><p>线程本地存储：<br>如果共享数据的代码可以在同一线程内执行完的话，就可以将共享数据的可见范围控制在同一线程内，在Java中可以使用ThreadLocal实现线程本地存储的功能。</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;在之前的理解中，以为一个类要么是线程安全的，要么是不安全的，但其实这里面还有细分和区别。此篇讨论一下多线程的不同安全级别，以及操作系统和程序是如何来实现线程安全的。</summary>
    
    
    
    
    <category term="并发" scheme="https://kevll.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>抓包分析TCP的三次握手</title>
    <link href="https://kevll.com/2018/06/06/%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90TCP%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/"/>
    <id>https://kevll.com/2018/06/06/%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90TCP%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B/</id>
    <published>2018-06-05T16:00:00.000Z</published>
    <updated>2022-12-19T10:50:35.702Z</updated>
    
    <content type="html"><![CDATA[<p>本篇记录一下利用wireshark抓tcp封包来分析tcp三次握手的过程，巩固一下网络基础知识。<span id="more"></span></p><h2 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h2><p>因为http是基于tcp的，所以在这里我就直接打开浏览器进行网页请求，打开wireshark，写好filter条件，开始capture：</p><p>回忆一下tcp报文的header信息，红色框内信息为握手过程交互的关键字段。</p><p><img src="/images/180606_tcp_header.jpg" alt="TCP header(图片来源网络)"></p><p>接下来根据实际请求来详细分析一下，访问我的blog地址，解析出的ip是151.101.1.147，我的本机ip为192.168.1.94，下图最上面的三条即为三次握手协议。为简述将本地称为A，远端称为B。</p><p><img src="/images/180606_tcp_shake1.png" alt="第一次握手"><br>将SYN置1；发送A的序号0</p><p><img src="/images/180606_tcp_shake2.png" alt="第二次握手"><br>将SYN、ACK置1；发送ACK number&#x3D;A的序号+1&#x3D;0+1&#x3D;1；发送B的序号0</p><p><img src="/images/180606_tcp_shake3.png" alt="第三次握手"><br>将ACK置1；发送ACK number&#x3D;B的序号+1&#x3D;0+1&#x3D;1<br>至此，双方的TCP连接就建立起来了，可以开始传送数据了。</p><h2 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h2><p>建立连接需要三次握手，为什么断开连接还需要四次挥手呢？下面简述一下四次挥手的过程</p><ol><li><p>A发起中断连接请求，就是发送FIN报文。和上面的SYN、ACK一样，FIN为一个bit的状态码，FIN&#x3D;1表示要中断连接。</p></li><li><p>B收到A的中断请求后，要回复A一个ACK告诉自己已经收到中断请求的消息了。但是B可能还有向A传输的数据没有完成，socket不能马上关闭，所以只能让A等待。</p></li><li><p>B的数据传输完毕之后，告诉A可以关闭连接了，发送FIN&#x3D;1给A。</p></li><li><p>A收到B的关闭请求后，就知道可以关闭连接了。为了防止B不知道要关闭，所以还要发送一次ACK给B，之后自己进入等待，如果B没有收到ACK则可以重传。B收到ACK后，就可以断开连接了。如果A等待了一定时间后没有收到回复，表示B已正常关闭，则自己也关闭连接，这样就完成了连接断开的全部操作。</p></li></ol><blockquote><p>断开连接比建立连接多了一次的原因就是：在建立连接时B端的SYN和ACK是可以同时发送的，但是在断开的时候，FIN字段必须要等到B端传输完成后才能发送，并不能像SYN一样能同ACK一起发送给客户端，所以多了一次等待和发送，这样有了4次挥手的过程。</p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;本篇记录一下利用wireshark抓tcp封包来分析tcp三次握手的过程，巩固一下网络基础知识。</summary>
    
    
    
    
    <category term="网络" scheme="https://kevll.com/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>JDK中的多线程</title>
    <link href="https://kevll.com/2018/04/18/JDK%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    <id>https://kevll.com/2018/04/18/JDK%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B/</id>
    <published>2018-04-17T16:00:00.000Z</published>
    <updated>2022-12-19T10:48:02.774Z</updated>
    
    <content type="html"><![CDATA[<p>开始在在多线程的坑中摸爬滚打。。<span id="more"></span></p><h2 id="让电脑做更多的事"><a href="#让电脑做更多的事" class="headerlink" title="让电脑做更多的事"></a>让电脑做更多的事</h2><p>Java学习到了后面，线程部分是相对来说难以理解和掌握的。初识线程时，知道它是电脑实现多任务的一种机制。然而在单核的CPU中并不是真正的同一时刻执行多个任务，而是不停地在线程间进行切换。好像多核的CPU可以真正的实现并发，但是自己还未涉及到。总的来说使用多线程可以让我们更好地利用系统资源去完成更多的事。</p><h2 id="开启一个线程"><a href="#开启一个线程" class="headerlink" title="开启一个线程"></a>开启一个线程</h2><p>Thread继承了一个接口Runnable，这个接口里只有一个方法run()，要让线程做的事也就写在run()里面。开启一个线程的方式为：new Thread(param).start()，param为实现了run()方法的Thread或Runnable对象。这时候线程就进入了就绪状态，等待CPU的调用了。</p><h2 id="同步与中断"><a href="#同步与中断" class="headerlink" title="同步与中断"></a>同步与中断</h2><p>多线程为我们带来高效的执行效果时，也同时增加了程序的复杂度，我们需要管理这些线程，并对程序中的数据进行安全化的处理。这时候线程间的同步和通信就显得尤为重要，Java里也提供了不同的机制让我们更好的使用多线程，有以下方法：<br>Object：</p><ul><li>wait()    线程等待，释放锁</li><li>notify()    线程唤起，释放锁</li></ul><p>Thread：</p><ul><li>sleep()    线程睡眠，不释放锁</li><li>interrupt()    通知线程中断</li></ul><p>Thread中还有方法：stop，suspend，resume，不过都不建议使用了，因为一个线程应该由自己来关闭。这里的interrupt()也不是真的中断了线程，而是将interrupt status设置为true，通知线程要停止操作了。线程需要自己扫描状态位，然后自己决定要做什么事，结束或是进行一些清理工作。</p><p>synchronized关键字；可以为代码块或是方法块加上同步锁，保证了操作的原子性。</p><h2 id="JDK5-之后的并发包"><a href="#JDK5-之后的并发包" class="headerlink" title="JDK5 之后的并发包"></a>JDK5 之后的并发包</h2><p>以上的都是传统多线程处理方法。jdk5之后增加了线程池、Callable和Future、锁对象Lock，可以让我们更轻松地去使用多线程来完成我们想要做的事。</p><h2 id="线程的三大特性"><a href="#线程的三大特性" class="headerlink" title="线程的三大特性"></a>线程的三大特性</h2><h3 id="原子性-可见性-有序性"><a href="#原子性-可见性-有序性" class="headerlink" title="原子性 可见性 有序性"></a>原子性 可见性 有序性</h3><p>这几个特性在线程的安全问题上必须要考虑周全了，缺一不可，不然就可能导致结果执行不正确。<br><strong>原子性</strong>：<br>即一个操作或者多个操作，为最小的不可分割的执行单位，执行的过程不会被任何因素打断。<br><strong>可见性</strong>：<br>当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。<br><strong>有序性</strong>：<br>程序执行的顺序按照代码的先后顺序执行。一般来说处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。</p><h2 id="JDK中的线程池"><a href="#JDK中的线程池" class="headerlink" title="JDK中的线程池"></a>JDK中的线程池</h2><p>jdk在5之后加入了concurrent包，提供了很多并发环境下实用的类，其中包括线程池ExecutorService。利用池化技术可以节省资源，提高性能，但是使用的不得当也会导致OOM，此篇说明线程池的核心参数和使用时的注意事项。<!--more--></p><h2 id="线程池核心参数"><a href="#线程池核心参数" class="headerlink" title="线程池核心参数"></a>线程池核心参数</h2><p>在使用线程池的过程中，很多人会使用Executors的静态方法去更便捷的创建一些线程池，主要有以下几种：</p><ul><li>newSingleThreadExecutor()</li><li>newFixedThreadPool(int nThreads)</li><li>newCachedThreadPool()</li><li>newScheduledThreadPool(int corePoolSize)</li></ul><p>阿里曾在他的开发手册中禁止开发人员使用Executors去创建线程池，而要使用ThreadPoolExecutor，为的应该是让开发人员多了解线程池的核心参数，避免使用不当。ThreadPoolExecutor也就是上面几个方法最后会调用的基础方法，其中的参数较多，如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public ThreadPoolExecutor(int corePoolSize,</span><br><span class="line">                          int maximumPoolSize,</span><br><span class="line">                          long keepAliveTime,</span><br><span class="line">                          TimeUnit unit,</span><br><span class="line">                          BlockingQueue&lt;Runnable&gt; workQueue,</span><br><span class="line">                          ThreadFactory threadFactory,</span><br><span class="line">                          RejectedExecutionHandler handler)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li>corePoolSize 核心线程数，表示线程池中一般工作时保持的线程数量。注意线程池在创建的时候并不会启动核心线程，而是等到有任务提交时才去创建线程，除非主动调用prestartCoreThread或者prestartAllCoreThreads，所以在任务不充足的情况下线程池的大小也不一定是corePoolSize。</li><li>maximumPoolSize 线程池内的最大线程数量，表示线程池中允许存在的最大线程数量，包含核心线程和非核心线程。</li><li>keepAliveTime 多余闲置线程存活时间，“多余”指的是超过核心线程数量的非核心线程，当它们执行完任务后，超过存活时间就会被销毁。</li><li>unit 存活时间单位</li><li>workQueue 任务队列，暂存还没有被执行的任务，只会保存通过execute方法提交的任务。</li><li>threadFactory 线程工厂，创建线程时用的线程工厂，默认是Executors.defaultThreadFactory()。</li><li>handler 任务拒绝策略，当任务队列满了并且线程池内线程数达到最大时，对新加任务的处理策略。默认是AbortPolicy，即丢弃新加的任务并抛出异常RejectedExecutionException。</li></ol><h3 id="线程池的整个工作流程如下入所示"><a href="#线程池的整个工作流程如下入所示" class="headerlink" title="线程池的整个工作流程如下入所示"></a>线程池的整个工作流程如下入所示</h3><p><img src="/images/200130_threadpool.png" alt="线程池工作逻辑"></p><h2 id="使用Executors的利弊"><a href="#使用Executors的利弊" class="headerlink" title="使用Executors的利弊"></a>使用Executors的利弊</h2><p>好处当然是使用更加便捷，Executors不需要去管那么多的核心参数，能立马上手创建线程池用于任务执行。但是Executors里的一些静态方法创建的线程池，其线程池和任务队列的大小是没有限制的，有OOM的风险。</p><h3 id="newSingleThreadExecutor"><a href="#newSingleThreadExecutor" class="headerlink" title="newSingleThreadExecutor()"></a>newSingleThreadExecutor()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public static ExecutorService newSingleThreadExecutor() &#123;</span><br><span class="line">    return new FinalizableDelegatedExecutorService</span><br><span class="line">        (new ThreadPoolExecutor(1, 1,</span><br><span class="line">                                0L, TimeUnit.MILLISECONDS,</span><br><span class="line">                                new LinkedBlockingQueue&lt;Runnable&gt;()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>new LinkedBlockingQueue()的队列长度为Integer.MAX_VALUE(0x7fffffff)，基本是个无界队列，所以可以往队列中无限地添加任务，有可能发生OOM。</p><h3 id="newFixedThreadPool-int-nThreads"><a href="#newFixedThreadPool-int-nThreads" class="headerlink" title="newFixedThreadPool(int nThreads)"></a>newFixedThreadPool(int nThreads)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public static ExecutorService newFixedThreadPool(int nThreads) &#123;</span><br><span class="line">    return new ThreadPoolExecutor(nThreads, nThreads,</span><br><span class="line">                                  0L, TimeUnit.MILLISECONDS,</span><br><span class="line">                                  new LinkedBlockingQueue&lt;Runnable&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>newFixedThreadPool与SingleThreadExecutor类似，区别就是核心线程数不同，使用的也是LinkedBlockingQueue，在资源有限的时候容易引起OOM异常。</p><h3 id="newCachedThreadPool"><a href="#newCachedThreadPool" class="headerlink" title="newCachedThreadPool()"></a>newCachedThreadPool()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">public static ExecutorService newCachedThreadPool() &#123;</span><br><span class="line">       return new ThreadPoolExecutor(0, Integer.MAX_VALUE,</span><br><span class="line">                                     60L, TimeUnit.SECONDS,</span><br><span class="line">                                     new SynchronousQueue&lt;Runnable&gt;());</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>核心线程数为0，最大线程数为Integer.MAX_VALUE，可以看作无限创建线程。而SynchronousQueue是一个不存储元素的队列，所以newCachedThreadPool每次将会创建非核心线程去执行任务。无限创建线程是一个很危险的动作，资源不足时会发生OOM。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;开始在在多线程的坑中摸爬滚打。。</summary>
    
    
    
    
    <category term="并发" scheme="https://kevll.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>分治与递归的分析</title>
    <link href="https://kevll.com/2018/03/07/%E5%88%86%E6%B2%BB%E4%B8%8E%E9%80%92%E5%BD%92%E7%9A%84%E5%88%86%E6%9E%90/"/>
    <id>https://kevll.com/2018/03/07/%E5%88%86%E6%B2%BB%E4%B8%8E%E9%80%92%E5%BD%92%E7%9A%84%E5%88%86%E6%9E%90/</id>
    <published>2018-03-06T16:00:00.000Z</published>
    <updated>2022-01-18T10:26:49.164Z</updated>
    
    <content type="html"><![CDATA[<p>此篇基于我在分析快速排序的时间复杂度时遇到的问题，我没能较好地理解它的运算模式。分治与递归是这个算法重要的两个部分，也比较难弄透，这篇详细分解下。<span id="more"></span></p><p>分治法将一个复杂的问题拆分成多个易解的小问题，最后将所有的解合并起来得到最终的答案。因为在拆分的过程中会出现逐层嵌套和分解的情况，所以这时候递归显得十分的适用。分治和递归像是一对好伙伴，经常在一起工作，因此也产生了许多高效的算法。快速排序就是很经典的一个运用，可是虽然了解实现原理，写起来也不是很熟练，因为里面包含一些边界问题和结束条件比较难把握。</p><p>了解算法运行过程最有效的方法就是分解其运行过程，下面分解下快速排序{6,10,12,14,3,5,23}的过程。</p><p>数组本身是无序的，我在这默认每次取当前排序组合中的第一位作为基准数，那么第一次排的数就是6，函数执行一遍后会将比6小的数都排在6之前，比6大的排在6之后。i，j分别表示当前组合的第一个索引位和最后一个索引位。这里有个边界问题，就是如果和基准数一样大的数该如何排列。其实一样大的数放在左边和右边都可以，最后的排序结果就是一样大的连在一起，选择一种即可。这里我写的是大于等于放在右边，小于放在左边。还有一个边界就是在步进后如果重合了，就不执行操作了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">while (i &lt; j) &#123;</span><br><span class="line">while (i &lt; j &amp;&amp; array[j] &gt;= x)//边界：小于x才满足放在左边的条件，所以j&gt;=x的时候是去找下一个数</span><br><span class="line">j--;</span><br><span class="line">if (i &lt; j)//边界：i，j重合，不执行操作</span><br><span class="line">array[i++] = array[j];</span><br><span class="line"></span><br><span class="line">while (i &lt; j &amp;&amp; array[i] &lt; x)</span><br><span class="line">i++;</span><br><span class="line">if (i &lt; j)</span><br><span class="line">array[j--] = array[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>()表示i的索引位置，[]表示j的索引位置。<br>排序开始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">初始：6为基准数</span><br><span class="line">(6),10,12,14,3,5,[23]</span><br><span class="line"></span><br><span class="line">1: j-</span><br><span class="line">(5),10,12,14,3,[5],23</span><br><span class="line"></span><br><span class="line">2: i+</span><br><span class="line">5,(10),12,14,3,[10],23</span><br><span class="line"></span><br><span class="line">3: j-</span><br><span class="line">5,(3),12,14,[3],10,23</span><br><span class="line"></span><br><span class="line">4: i+</span><br><span class="line">5,3,(12),14,[12],10,23</span><br><span class="line"></span><br><span class="line">5: j- 与i重合</span><br><span class="line">5,3,[(12)],14,12,10,23</span><br><span class="line"></span><br><span class="line">将基准数填入重合索引位:</span><br><span class="line">5,3,6,14,12,10,23</span><br></pre></td></tr></table></figure><p>此时以6为基准数的第一遍排序已经完成，这时候原来的7位数的排序问题就被分成了2个小数组排序的问题。这里也有一个边界问题，就是6的所在位置就是它的最终位置，所以剩下的两个无序数组为：5，3和14，12，10，23。开始递归剩下来的数组时，就可以把6的位置排除了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">//递归调用</span><br><span class="line">quick_sort(array, left, i - 1);//i为重合处索引</span><br><span class="line">quick_sort(array, i + 1, right);</span><br></pre></td></tr></table></figure><p>第一行递归：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">初始：5为基准数</span><br><span class="line">(5),[3]</span><br><span class="line"></span><br><span class="line">1: j未减已满足比5小</span><br><span class="line">(3),[3]</span><br><span class="line"></span><br><span class="line">2：i++</span><br><span class="line">3,([3])</span><br><span class="line"></span><br><span class="line">将基准数填入重合索引位:</span><br><span class="line">3,5</span><br></pre></td></tr></table></figure><p>此时left&#x3D;0，i&#x3D;1，即调用quick_sort(array, left, i - 1)-&gt;quick_sort(array,0,0);到达了函数的终止条件。这个终止条件并没有显示的写出，可以再看下函数的限制：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if (left &lt; right) &#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也就是说，当left和right相同时，不满足函数的继续执行条件，而对递归的调用也在方法块中，自然也不会执行。这个递归就到此结束了。这时候第一行递归已经全部完成，执行第二行递归。这里用的数组较小，如果没排完将一直循环递归下去，直到当前组合全部排序完毕。此时3，5，6的最终位置都已完成，最后将6右边比6大的数组按照以上同样的方式递归完后，整个数组排序就完成了。</p><p>last-updated: 2018-03-15</p><p>参考：<br><a href="http://blog.csdn.net/morewindows/article/details/6684558">MoreWindows 白话经典算法系列之六</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;此篇基于我在分析快速排序的时间复杂度时遇到的问题，我没能较好地理解它的运算模式。分治与递归是这个算法重要的两个部分，也比较难弄透，这篇详细分解下。</summary>
    
    
    
    
    <category term="算法" scheme="https://kevll.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>快速排序的O(nlogn)是如何计算的</title>
    <link href="https://kevll.com/2018/02/19/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%9A%84O(nlogn)%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E7%9A%84/"/>
    <id>https://kevll.com/2018/02/19/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E7%9A%84O(nlogn)%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E7%9A%84/</id>
    <published>2018-02-18T16:00:00.000Z</published>
    <updated>2022-12-19T10:54:57.804Z</updated>
    
    <content type="html"><![CDATA[<p>在学习算法的过程当中，涉及到了算法的效率问题，这里有一个时间复杂度可以用来衡量算法在时间上的消耗，当时看冒泡排序的时间复杂度很好理解，但是快速排序的nlogn就弄不明白了，决定研究一下。<span id="more"></span></p><p>这里回顾下冒泡的时间复杂度计算过程，比较简单，我们一般在写冒泡排序的代码时，就是套上了2层循环，其中对n的值进行变化。冒泡排序实际是拿每一个元素和后面的元素进行依次比较，所以每轮比较后将会把当前未排序的数字中最大或最小的值排到最后，故每次比较的次数都会减一，也就是第二层循环会递减，排完n-1次后，第一个数不需要再排列，其时间复杂度的计算过程如下：</p><p>(n-1)+(n-2)+(n-3)+…+1+0 一共n个数的比较过程<br>(n-1)*(n-1+1)&#x2F;2&#x3D;(n^2-n)&#x2F;2<br>舍弃低次幂得到O&#x3D;n^2</p><p>快速排序用的是分治法加递归，这里贴上java的实现代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">static void quick_sort(int array[], int left, int right) &#123;</span><br><span class="line">if (left &lt; right) &#123;</span><br><span class="line">int i = left; </span><br><span class="line">int j = right;</span><br><span class="line">int x = array[left];//选取第一个数为基准数</span><br><span class="line"></span><br><span class="line">while (i &lt; j) &#123;</span><br><span class="line">while (i &lt; j &amp;&amp; array[j] &gt;= x)</span><br><span class="line">j--;</span><br><span class="line">if (i &lt; j)</span><br><span class="line">array[i++] = array[j];</span><br><span class="line"></span><br><span class="line">while (i &lt; j &amp;&amp; array[i] &lt; x)</span><br><span class="line">i++;</span><br><span class="line">if (i &lt; j)</span><br><span class="line">array[j--] = array[i];</span><br><span class="line">&#125;</span><br><span class="line">array[i] = x;</span><br><span class="line"></span><br><span class="line">//递归调用</span><br><span class="line">quick_sort(array, left, i - 1);</span><br><span class="line">quick_sort(array, i + 1, right);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有一个叫主定理的东西：T [n] &#x3D; aT[n&#x2F;b] + f (n)<br>其中 a &gt;&#x3D; 1 and b &gt; 1 是常量 并且 f (n) 是一个渐近正函数，为了使用这个主定理，需要考虑下列三种情况：<br><img src="/images/180529_master_method.jpg" alt="主定理的三种情况(图片来源网络)"></p><p>快排每次把一个问题分成两个子问题，则有：<br>T[n]&#x3D;2T[n&#x2F;2]+O(n), O(n)为partition()的时间复杂度。<br>对比主定理，此时的a&#x3D;2, b&#x3D;2, f(n)&#x3D;O(n)<br>那么：n<sup>log<sub>b</sub>a</sup>&#x3D;n, 属于case2，所以快排的时间复杂度为O(nlogn)</p><p>说实话，我还是有点迷糊，这里只有一个公式，并不知道公式是怎么来的，而且还有其它的计算方法。后来还了解到涉及到分治和递归的算法的时间复杂度都会有log，这块还要抽空回过头来研究一下。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在学习算法的过程当中，涉及到了算法的效率问题，这里有一个时间复杂度可以用来衡量算法在时间上的消耗，当时看冒泡排序的时间复杂度很好理解，但是快速排序的nlogn就弄不明白了，决定研究一下。</summary>
    
    
    
    
    <category term="算法" scheme="https://kevll.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>深入理解HashMap</title>
    <link href="https://kevll.com/2018/01/25/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3HashMap/"/>
    <id>https://kevll.com/2018/01/25/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3HashMap/</id>
    <published>2018-01-24T16:00:00.000Z</published>
    <updated>2022-01-18T10:26:49.167Z</updated>
    
    <content type="html"><![CDATA[<p>之前浅显地了解过HashMap是由数组加上链表实现的，但是一直没有真正理解到他的结构到底是怎样的，现在记录下自己学习HashMap的过程和理解，本篇研究了put与resize的源码实现、HashMap的关于桶大小及扩展的一些细节、以及jdk1.8做了哪些优化。<span id="more"></span><!-- more --></p><h2 id="数组与链表的结合"><a href="#数组与链表的结合" class="headerlink" title="数组与链表的结合"></a>数组与链表的结合</h2><p>在之前的学习中，了解到数组在内存中是一组连续的存储。它便于遍历和查询，但是不方便插入和删除。例如在一个存储了100个元素的ArrayList中，在索引为50的位置插入一个元素，则从索引为50开始往后的所有元素都需要后移，这无疑是非常大的消耗。但数组的查找时间复杂度小，为O(1)。而链表是一种离散的存储，插入和删除只需要修改链接的指向，但搜索的时间复杂度达到O(n)。<br>所以在HashMap中结合了两者的特性，让HashMap成为了一种寻址容易，插删也容易的数据结构。在这里用到的就是哈希表，哈希表为了解决冲突，主要有两种实现方法：开放地址法和链地址法。在HashMap中使用的是链地址法，也可称为拉链法，可理解为“链表的数组”。</p><p>HashMap中，有一个重要的Node[] table，Node实现了Map的静态内部类Entry，其中重要的属性有key，value，next，保存的就是键值对和到下一个Node的引用。</p><h2 id="put与get的基本操作"><a href="#put与get的基本操作" class="headerlink" title="put与get的基本操作"></a>put与get的基本操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//存储</span><br><span class="line">int hash=key.hashCode();</span><br><span class="line">int index=hash&amp;(Entry[].length-1);</span><br><span class="line">Entry[index]=value;</span><br><span class="line">//取值</span><br><span class="line">int hash=key.hashCode();</span><br><span class="line">int index=hash&amp;(Entry[].length-1);</span><br><span class="line">return Entry[index];</span><br></pre></td></tr></table></figure><p>这样，就基本将键值对均匀的分布在了数组中。<br>如果两个key经过hash后得到的index相同，会发生什么？例如Entry[0]&#x3D;A之后，又来了一个元素B，其经过运算后的index也是0。这时就要用到链表的结构了，前面说道Entry有一个为next的属性，所以此时B.next&#x3D;A，Entry[0]&#x3D;B。Entry[0]处将一直存储着最后插入的元素。</p><h2 id="代码详细剖析"><a href="#代码详细剖析" class="headerlink" title="代码详细剖析"></a>代码详细剖析</h2><p>jdk1.8，put-&gt;putVal</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">final V putVal(int hash, K key, V value, boolean onlyIfAbsent,</span><br><span class="line">               boolean evict) &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab;    //HashMap的元素数组</span><br><span class="line">    Node&lt;K,V&gt; p;        //数组中准备插入的索引位置的原始Node</span><br><span class="line">   </span><br><span class="line">    int n, i;           //n：元素数组的长度，i：准备插入的经过hash运算过后的索引值</span><br><span class="line">    </span><br><span class="line">    if ((tab = table) == null || (n = tab.length) == 0) //如果元素数组为null或长度为0，则resize</span><br><span class="line">        n = (tab = resize()).length;</span><br><span class="line">    if ((p = tab[i = (n - 1) &amp; hash]) == null)          //如果原索引处为空，新建一个Node</span><br><span class="line">        tab[i] = newNode(hash, key, value, null);</span><br><span class="line">    else &#123;</span><br><span class="line">        Node&lt;K,V&gt; e; </span><br><span class="line">        K k;    //原始key</span><br><span class="line">        </span><br><span class="line">        //如果索引处有原始Node，且key值相同，赋给e</span><br><span class="line">        if (p.hash == hash &amp;&amp;   </span><br><span class="line">            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) </span><br><span class="line">            e = p;</span><br><span class="line"></span><br><span class="line">        //如果为TreeNode，直接插入红黑树</span><br><span class="line">        else if (p instanceof TreeNode)</span><br><span class="line">            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);</span><br><span class="line"></span><br><span class="line">        //遍历链表准备插入</span><br><span class="line">        else &#123;</span><br><span class="line">            for (int binCount = 0; ; ++binCount) &#123;</span><br><span class="line">                //如果Node的next为空，插入next</span><br><span class="line">                if ((e = p.next) == null) &#123;</span><br><span class="line">                    p.next = newNode(hash, key, value, null);</span><br><span class="line">                    //如果链表的长度超过了阈值（默认为8），转为红黑树处理</span><br><span class="line">                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st</span><br><span class="line">                        treeifyBin(tab, hash);</span><br><span class="line">                    break;</span><br><span class="line">                &#125;</span><br><span class="line">                //如果插入元素与next的key值相同，直接覆盖</span><br><span class="line">                if (e.hash == hash &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">                    break;</span><br><span class="line">                //链表后移一位</span><br><span class="line">                p = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if (e != null) &#123; // existing mapping for key</span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            if (!onlyIfAbsent || oldValue == null)</span><br><span class="line">                e.value = value;</span><br><span class="line">            afterNodeAccess(e);</span><br><span class="line">            return oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    ++modCount;  //表结构修改次数增加</span><br><span class="line">   </span><br><span class="line">    if (++size &gt; threshold)  //如果增加后的元素数目超过了阈值，则resize</span><br><span class="line">        resize();</span><br><span class="line">    afterNodeInsertion(evict);</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>1.8的扩容代码好像有点复杂，包含红黑树，先分析一下jdk1.7的resize</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void resize(int newCapacity) &#123;</span><br><span class="line">    Entry[] oldTable = table;</span><br><span class="line">    int oldCapacity = oldTable.length;         </span><br><span class="line">    if (oldCapacity == MAXIMUM_CAPACITY) &#123;  //如果元素超过了最大容量1&lt;&lt;20(2^30) 1048576</span><br><span class="line">      threshold = Integer.MAX_VALUE;</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    Entry[] newTable = new Entry[newCapacity];</span><br><span class="line">    transfer(newTable);</span><br><span class="line">    table = newTable;</span><br><span class="line">    threshold = (int)(newCapacity * loadFactor);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>transfer()将原有Entry数组的元素拷贝至新的容量更大的数组。拷贝后旧数组同一条Entry链上的元素可能将被放到不同位置上，因为元素的索引都经过了重新计算。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">void transfer(Entry[] newTable) &#123;</span><br><span class="line">    Entry[] src = table;</span><br><span class="line">   int newCapacity = newTable.length;</span><br><span class="line">   for (int j = 0; j &lt; src.length; j++) &#123;</span><br><span class="line">      Entry&lt;K,V&gt; e = src[j];</span><br><span class="line">      if (e != null) &#123;</span><br><span class="line">        src[j] = null;//释放原数组索引位置对象，等待回收</span><br><span class="line">        do &#123;</span><br><span class="line">           Entry&lt;K,V&gt; next = e.next;</span><br><span class="line">           int i = indexFor(e.hash, newCapacity); //重新计算索引</span><br><span class="line">           e.next = newTable[i]; //头插入，新元素.next指向原第一位元素(第一次指向null)</span><br><span class="line">           newTable[i] = e;      //将最新的元素放在数组第一位</span><br><span class="line">           e = next;             //遍历后移</span><br><span class="line">           &#125; while (e != null);</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="容量与负载因子"><a href="#容量与负载因子" class="headerlink" title="容量与负载因子"></a>容量与负载因子</h2><p>在HashMap中，有两个重要的值，它们是桶容量和负载因子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * The default initial capacity - MUST be a power of two.</span><br><span class="line"> */</span><br><span class="line">static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * The load factor used when none specified in constructor.</span><br><span class="line"> */</span><br><span class="line">static final float DEFAULT_LOAD_FACTOR = 0.75f;</span><br></pre></td></tr></table></figure><p>默认的初始容量是16、负载因子是0.75。HashMap当前能存放的最大数据量threshold&#x3D;(容量*负载因子)，超过这个数据量就要进行扩容，扩容后是之前容量的2倍。默认的0.75负载因子是一个对时间和空间的均衡，一般的情况下都不需要修改，如果场景比较特殊，比如内存很多而对时间效率要求高就可以降低负载因子的值；而如果内存紧张对时间效率要求也不高的话就可以增加负载因子的值，这个值可以超过1。</p><h2 id="2次方桶的作用"><a href="#2次方桶的作用" class="headerlink" title="2次方桶的作用"></a>2次方桶的作用</h2><p>在HashMap中，哈希桶的大小必须是2的N次方（一定是合数）。一般情况下，素数导致冲突的概率要小于合数，HashTable初始化桶的大小为11就是素数的应用。HashMap这样设计是为了在hash取模和扩容的时候做优化。接下来看下HashMap的hash算法和扩容机制，下面是hash算法与优化的取模运算：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//HashMap在put值的时候，将先执行一遍hash算法，计算hash</span><br><span class="line">public V put(K key, V value) &#123;</span><br><span class="line">    return putVal(hash(key), key, value, false, true);</span><br><span class="line">&#125;</span><br><span class="line">//hash算法</span><br><span class="line">static final int hash(Object key) &#123;</span><br><span class="line">    int h;</span><br><span class="line">    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</span><br><span class="line">&#125;</span><br><span class="line">//取模，1.8没有这个方法，取模运算放在了具体调用的地方</span><br><span class="line">static int indexFor(int h, int length) &#123;</span><br><span class="line">    return h &amp; (length-1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在平均一批元素的时候，我们常常的操作就是直接对容器的容量大小进行取模运算，这样元素的分布式相对比较均匀的。但是在计算机中模运算的消耗是比较大的，当桶的大小是2的n次方时，总有h%length &#x3D; h&amp;(length-1)。这个取模运算的效率是非常重要的，因为在put和get时，对元素的索引进行计算的时候都要经过这个方法，而&amp;比%有更高的效率。</p><p>hash算法越分散均匀，hash碰撞的概率就越小，map的存取效率就越高。</p><p>1.8之后，使用的是2次幂的扩展，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。所以，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。</p><p>参考：<br><a href="https://zhuanlan.zhihu.com/p/21673805">美团点评技术团队：Java8系列之重新认识HashMap</a><br><a href="https://monkeysayhi.github.io/2017/08/26/HashMap%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/">猴子007：HashMap实现原理</a><br><a href="https://www.cnblogs.com/softidea/p/7261111.html">沧海一滴：深入理解HashMap</a><br>jdk1.7, jdk1.8 源码</p><p>last update: 2018-06-27</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;之前浅显地了解过HashMap是由数组加上链表实现的，但是一直没有真正理解到他的结构到底是怎样的，现在记录下自己学习HashMap的过程和理解，本篇研究了put与resize的源码实现、HashMap的关于桶大小及扩展的一些细节、以及jdk1.8做了哪些优化。</summary>
    
    
    
    
    <category term="源码" scheme="https://kevll.com/tags/%E6%BA%90%E7%A0%81/"/>
    
    <category term="数据结构" scheme="https://kevll.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
</feed>
